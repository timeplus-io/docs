# Overview

Unlike traditional streaming processors such as Flink or ksqlDB, **Timeplus** allows you to **store data natively** in the platform, enabling multiple scenarios:

1. **Ingest raw data** into Timeplus for reliable processing or reprocessing.  
2. **Store intermediate results** generated by Materialized Views or Tasks, and perform cascading queries on these results.  
3. **Store final processed results** that are ready to be served directly to applications.  

This means Timeplus can function as a **standalone, self-contained platform** to manage the entire data lifecycle â€” from ingest to process to serve.  

Alternatively, it can integrate seamlessly with your existing infrastructure (e.g., upstream **Kafka**, **Pulsar**, **PostgreSQL**; downstream **ClickHouse**, **S3**, etc.).  

This flexibility gives you full control to optimize for **performance, cost-efficiency, and latency** based on your use case.

## Storage Engines

There is no single storage engine that performs best across all scenarios. To address this, Timeplus provides several built-in **storage engines**, each optimized for different use cases. The architecture is extensible, making it possible to add new engines as needed.

At a high level, Timeplus supports three categories of storage engines:

1. **Columnar Store**  
   - Different Flavors: `changelog_kv`, `versioned_kv`, and `append_stream`.  
   - Optimized for analytical queries and high-throughput streaming persistence.

2. **Row Store**  
   - Implementation: `mutable_stream`.  
   - Optimized for high concurrent mutable, row-oriented workloads.

3. **Dictionary**  
   - A special key/value storage engine.  
   - Acts as a cached lookup table, highly effective when combined with joins or remote lookups.

Each engine involves trade-offs in terms of **latency, throughput, mutability, and query patterns**. You can refer to their dedicated documentation for deeper details.

## Data Serving

Once data is persisted in Timeplus, it can be served in two modes:

- **Streaming queries** for real-time, continuous insights.  
- **Historical queries** for ad-hoc or backfill analysis.  

Applications can access the data via multiple interfaces:

- **SDKs / Drivers** (language-specific)  
- **WebSocket API**  
- **Timeplus Native Client**  
- **Timeplus Web Console**  

Data delivery is flexible: it can be **pushed to clients** (pub/sub style) or **pulled on demand** by applications. The choice depends on your integration and latency requirements.
